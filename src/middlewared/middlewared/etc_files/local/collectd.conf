<%
	import os
	import psutil
	import shutil
	import subprocess
	import sys
	import tarfile
	import time


	systemdataset_config = middleware.call_sync('systemdataset.config')
	is_freenas = middleware.call_sync('system.is_freenas')
	rrd_mount = "" if not systemdataset_config['path'] else f'{systemdataset_config["path"]}/rrd-{systemdataset_config["uuid"]}'
	if rrd_mount or not systemdataset_config['rrd'] or (not is_freenas and middleware.call_sync('notifier.failover_status' == 'BACKUP')):
		use_rrd_dataset = True
	else:
		use_rrd_dataset = False

	# TODO: FreeNAS Config MD5 is hardcoded, this should be looked in future to see if we can change that
	# If there is a failover table remove the rc.conf cache rc.conf.local will run again using the correct collectd_enable
	# See #5019
	if is_freenas:
		try:
			os.remove('/var/tmp/freenas_config.md5')
		except FileNotFoundError:
			pass

	hostname = middleware.call_sync('system.info')['hostname'] or "freenas.local"  # Or added for first boot cases where hostname cannot be retrieved via socket.gethostbyname call
	advanced_config = middleware.call_sync('system.advanced.config')
	graphite = advanced_config['graphite']
	cpu_in_percentage = advanced_config['cpu_in_percentage']

	rrd_file = '/data/rrd_dir.tar.bz2'
	base_dir = '/var/db/collectd'
	data_dir = '/var/db/collectd/rrd'
	disk_parts = psutil.disk_partitions()
	data_dir_is_ramdisk = len([d for d in disk_parts if d.mountpoint == data_dir and d.device == 'tmpfs']) > 0

	def remove(path, link_only=False):
		if os.path.exists(path):
			if os.path.islink(path):
				os.unlink(path)
			elif os.path.isdir(path) and not link_only:
				shutil.rmtree(path)
			elif not link_only:
				os.remove(path)

	def run_cmd(cmd):
		subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, close_fds=True).communicate()

	if use_rrd_dataset:
		if os.path.isdir(rrd_mount):
			if os.path.isdir(data_dir) and not os.path.islink(data_dir):
				if data_dir_is_ramdisk:
					# copy-umount-remove
					run_cmd(f'cp -a "{data_dir}" "{data_dir}.{time.strftime("%Y%m%d%H%M%S")}"')

					# Should we raise an exception if umount fails ?
					run_cmd(f'umount {data_dir}')

					remove(data_dir)
				else:
					shutil.move(data_dir, f'{data_dir}.{time.strftime("%Y%m%d%H%M%S")}')

			if data_dir != rrd_mount:
				remove(data_dir)
				os.symlink(rrd_mount, data_dir)
		else:
			middleware.logger.error(f'{rrd_mount} does not exist or is not a directory')
			sys.exit(1)
	else:
		remove(data_dir, link_only=True)

		if not os.path.isdir(data_dir):
			os.makedirs(data_dir)

		# Create RAMdisk (if not already exists) for RRD files so they don't fill up root partition
		if not data_dir_is_ramdisk:
			run_cmd(f'mount -t tmpfs -o size=1g tmpfs {data_dir}')

	if use_rrd_dataset:
		if not os.path.exists(rrd_mount):
			middleware.logger.error(f'{rrd_mount} does not exist')
			sys.exit(1)
		else:
			pwd = rrd_mount
	else:
		if not os.path.exists(data_dir):
			middleware.logger.error(f'{data_dir} does not exist')
			sys.exit(1)
		else:
			pwd = data_dir

	def get_members(tar, prefix):
		for tarinfo in tar.getmembers():
			if tarinfo.name.startswith(prefix):
				tarinfo.name = tarinfo.name[len(prefix):]
				yield tarinfo

	if os.path.isfile(rrd_file):
		with tarfile.open(rrd_file) as tar:
			if 'collectd/rrd' in tar.getnames():
				tar.extractall(pwd, get_members(tar, 'collectd/rrd/'))

		if use_rrd_dataset:
			remove(rrd_file)

	# Migrate from old version, where "${hostname}" was a real directory
	# and "localhost" was a symlink.
	# Skip the case where "${hostname}" is "localhost", so symlink was not
	# (and is not) needed.
	if hostname != 'localhost' and os.path.isdir(os.path.join(pwd, hostname)) and not os.path.islink(os.path.join(pwd, hostname)):
		if os.path.isfile(os.path.join(pwd, 'localhost')):
			if os.path.islink(os.path.join(pwd, 'localhost')):
				remove(os.path.join(pwd, 'localhost'))
			else:
				# This should not happen, but just in case
				shutil.move(os.path.join(pwd, 'localhost'), os.path.join(pwd, f'localhost.bak.{time.strftime("%Y%m%d%H%M%S")}'))
		shutil.move(os.path.join(pwd, hostname), os.path.join(pwd, 'localhost'))

	# Remove all directories except "localhost" and it's backups (that may be erroneously created by
	# running collectd before this script)
	to_remove_dirs = [os.path.join(pwd, d) for d in os.listdir(pwd) if not d.startswith('localhost') and os.path.isdir(os.path.join(pwd, d))]
	for r_dir in to_remove_dirs:
		remove(r_dir)

	# Remove all symlinks (that are stale if hostname was changed).
	to_remove_symlinks = [os.path.join(pwd, l) for l in os.listdir(pwd) if os.path.islink(os.path.join(pwd, l))]
	for r_symlink in to_remove_symlinks:
		remove(r_symlink)

	# Create "localhost" directory if it does not exist
	if 'localhost' not in os.listdir(pwd):
		os.makedirs(os.path.join(pwd, 'localhost'))

	# Create "${hostname}" -> "localhost" symlink if necessary
	if hostname != 'localhost':
		os.symlink(os.path.join(pwd, 'localhost'), os.path.join(pwd, hostname))

	if cpu_in_percentage:
		cpu_plugin_options = 'ValuesPercentage True'
		aggregation_plugin_cpu_type = 'percent'
	else:
		cpu_plugin_options = ''
		aggregation_plugin_cpu_type = 'cpu'

%>
Hostname "${hostname}"
FQDNLookup true
BaseDir "${base_dir}"
PIDFile "/var/run/collectd.pid"
PluginDir "/usr/local/lib/collectd"

LoadPlugin aggregation
LoadPlugin cpu
LoadPlugin cputemp
LoadPlugin ctl
LoadPlugin df
LoadPlugin disk
LoadPlugin exec
LoadPlugin geom_stat
LoadPlugin interface
LoadPlugin load
LoadPlugin memory
LoadPlugin network
LoadPlugin processes
LoadPlugin python
LoadPlugin rrdtool
LoadPlugin swap
LoadPlugin uptime
LoadPlugin syslog
LoadPlugin threshold
LoadPlugin zfs_arc
LoadPlugin zfs_arc_v2
LoadPlugin nfsstat

<Plugin "syslog">
	LogLevel err
</Plugin>

<Plugin "aggregation">
	<Aggregation>
		Plugin "cpu"
		Type "${aggregation_plugin_cpu_type}"
		GroupBy "Host"
		GroupBy "TypeInstance"
		CalculateNum true
		CalculateSum true
		CalculateAverage true
		CalculateMinimum true
		CalculateMaximum true
		CalculateStddev true
	</Aggregation>
</Plugin>
<Plugin cpu>
	${cpu_plugin_options}
</Plugin>

<Plugin cputemp>
</Plugin>

<Plugin "disk">
	Disk "/^gptid/"
	Disk "/^md/"
	Disk "/^pass/"
	IgnoreSelected true
</Plugin>

<Plugin "exec">
	NotificationExec "nobody" "/usr/local/www/freenasUI/tools/collectd_alert.py"
</Plugin>

<Plugin "interface">
	Interface "lo0"
	Interface "ipfw0"
	Interface "pflog0"
	Interface "pfsync0"
	Interface "plip0"
	Interface "/^usbus/"
	IgnoreSelected true
</Plugin>

<Plugin "rrdtool">
	DataDir "${data_dir}"
% if use_rrd_dataset:
	CacheTimeout 120
	CacheFlush 900
% endif
</Plugin>

<Plugin "threshold">
	<Plugin "ctl">
		Instance "ha"
		<Type "disk_octets">
			WarningMax 10000000
			Persist true
			Interesting false
		</Type>
	</Plugin>
</Plugin>

<Plugin "zfs_arc">
</Plugin>

<Plugin "geom_stat">
	Filter "^([a]?da|ciss|md|mfi|md|nvd|pmem|xbd|vtbd)[0123456789]+$"
</Plugin>

<Plugin "df">
	Mountpoint "/"
	Mountpoint "^\/mnt(?:(?!\.zfs\/snapshot).)*$"
	FSType "zfs"
	LogOnce true
</Plugin>

<Plugin python>
	ModulePath "/usr/local/lib/collectd_pyplugins"
	LogTraces true
	Interactive false
	Import "disktemp"

	<Module "disktemp">
	</Module>
</Plugin>
% if graphite:

LoadPlugin write_graphite
<Plugin "write_graphite">
	<Node "graphite">
		Host "${graphite}"
		Port "2003"
		Protocol "tcp"
		LogSendErrors true
		Prefix "servers."
		Postfix ""
		StoreRates true
		AlwaysAppendDS false
		EscapeCharacter "_"
	</Node>
</Plugin>
% endif
